{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_1b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZqsjy4J-j65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "78957433-1f96-43aa-ffb1-50bba18768eb"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "from keras.datasets import cifar10, mnist\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from keras.models import load_model\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import Callback\n",
        "from keras.regularizers import Regularizer, L1L2\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"Done loading data\")\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Done loading data\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNXM6Nyt_HtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "taskA_indx_train = np.where((y_train==0)|(y_train==1)|(y_train==2)|(y_train==3)|(y_train==4))[0]\n",
        "taskA_indx_test = np.where((y_test==0)|(y_test==1)|(y_test==2)|(y_test==3)|(y_test==4))[0]\n",
        "\n",
        "taskB_indx_train = np.setdiff1d(np.arange(y_train.shape[0]), taskA_indx_train)\n",
        "taskB_indx_test = np.setdiff1d(np.arange(y_test.shape[0]), taskA_indx_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5qHNzc4OjOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "# x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "# x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "# x_train /= 255\n",
        "# x_test /= 255\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS9czOLf_R6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultitaskCallback(Callback):\n",
        "  \n",
        "  def __init__(self, main_task, previous_task=None):\n",
        "    self.main_task = main_task\n",
        "    self.previous_task = previous_task\n",
        "    self.main_task_preds=[]\n",
        "    self.previous_task_preds=[]\n",
        "    self.batch_counter = 0\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    if self.batch_counter %25 == 0:\n",
        "      x,y = self.main_task\n",
        "      predsA = self.model.evaluate(x,y)[1]\n",
        "      print(f\"Evaluation results Main {predsA}\")\n",
        "      self.main_task_preds.append(1-predsA)\n",
        "      \n",
        "      if self.previous_task:\n",
        "        x2,y2 = self.previous_task\n",
        "        predsB = self.model.evaluate(x2, y2)[1]\n",
        "        print(f\"Evaluation results Previous {predsB}\")\n",
        "        self.previous_task_preds.append(1-predsB)\n",
        "    self.batch_counter +=1\n",
        "\n",
        "class EWC_Regularizer(Regularizer):\n",
        "  lam = 8000\n",
        "  def __init__(self, layer_indx, fim, star_weights, is_ewc):\n",
        "    self.layer_indx = layer_indx\n",
        "    self.fim = fim\n",
        "    self.star_weights = star_weights\n",
        "    self.is_ewc = is_ewc\n",
        "\n",
        "  def __call__(self, x):\n",
        "    penalty = x\n",
        "    if self.is_ewc:\n",
        "      l2 = K.square(x - self.star_weights[self.layer_indx])\n",
        "      # + K.sum(np.abs(x)\n",
        "      penalty = self.lam/2 * (K.sum(self.fim[self.layer_indx] * l2))\n",
        "    return penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IniArBh_A5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "c60d042c-b833-45e2-d1f5-5c8f25ceeaff"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), padding='same',\n",
        "#                  input_shape=(28,28,1)))\n",
        "# model.add(Activation('relu'))\n",
        "# # model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Conv2D(64,(3,3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Conv2D(128,(3,3),padding='same'))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv2D(128,(3,3), padding='same'))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv2D(128,(3,3),padding='same'))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Flatten())\n",
        "model.add(Dense(128, input_shape=(28*28,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLMRe_-LANCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard = keras.callbacks.TensorBoard('/content/drive/My Drive/forgetting/taskA')\n",
        "# print(taskA_indx_train)\n",
        "# taskA_callback = MultitaskCallback((x_test[taskA_indx_test], y_test[taskA_indx_test][:, :5]))\n",
        "# model.fit(x_train[taskA_indx_train], \n",
        "#           y_train[taskA_indx_train][:, :5],\n",
        "#           callbacks=[taskA_callback],\n",
        "#           batch_size=32,\n",
        "#           epochs=5,\n",
        "#           validation_data=(x_test[taskA_indx_test],y_test[taskA_indx_test][:, :5])\n",
        "#           )\n",
        "# model.save_weights('/content/drive/My Drive/model/ewc_model_mnist.h5')\n",
        "\n",
        "# tensorboard = keras.callbacks.TensorBoard('/content/drive/My Drive/forgetting/taskA')\n",
        "# print(taskA_indx_train)\n",
        "taskA_callback = MultitaskCallback((x_test[taskA_indx_test], y_test[taskA_indx_test]))\n",
        "model.fit(x_train[taskA_indx_train], \n",
        "          y_train[taskA_indx_train],\n",
        "          callbacks=[taskA_callback],\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test[taskA_indx_test],y_test[taskA_indx_test])\n",
        "          )\n",
        "model.save_weights('/content/drive/My Drive/model/ewc_model_mnist.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqae0WeYQBGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save_weights('/content/drive/My Drive/model/ewc_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbJY6xE2AGfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [layer for layer in model.layers if 'conv' in layer.name or 'dense' in layer.name]\n",
        "# for layer in layers:\n",
        "#   print(layer.name)\n",
        "#   print(layer.trainable_weights[0])\n",
        "#   # for i in range(len(layer.get_weights())):\n",
        "#   #   print(len(layer.get_weights()[i]))\n",
        "# Star theta: final weights of trained model\n",
        "# print(np.isnan(model.weights).any())\n",
        "weights = [layer.trainable_weights[0] for layer in layers ]\n",
        "# for layer in layers:\n",
        "#   w = layer.trainable_weights[0]\n",
        "#   # print(w.numpy)\n",
        "#   print(tf.reduce_any(tf.math.is_nan(w)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRXNeBmfSQRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "def compute_fisher(model, x, num_samples):\n",
        "  fisher = []\n",
        "  x = x[:num_samples]\n",
        "  len_x = len(x)\n",
        "  for weight in weights:\n",
        "    fisher.append(K.zeros(weight.shape))\n",
        "\n",
        "  for i,data in enumerate(x):\n",
        "    data = np.expand_dims(data, axis=0)\n",
        "    probs = model.predict([data])[0]\n",
        "    indx = np.argmax(probs)\n",
        "    # grads = K.gradients(K.log(probs[indx]), weights)\n",
        "    grads = K.gradients(K.log(model.output), weights)\n",
        "    grads_compute = K.function(model.input, grads)\n",
        "    ders = grads_compute(data)\n",
        "    # print(f\"Shape of ders {len(ders)} and # of layers {len(weights)}\")\n",
        "    for w_indx in range(len(fisher)):\n",
        "      # print(fisher[w_indx].shape)\n",
        "      # print(ders[w_indx])\n",
        "      fisher[w_indx] = fisher[w_indx] + K.square(ders[w_indx])\n",
        "    \n",
        "    if i%100 == 0:\n",
        "      print(f\"Iteration {i}/{len_x}\")\n",
        "  \n",
        "\n",
        "  for w_indx in range(len(fisher)):\n",
        "    fisher[w_indx] /= len(x)\n",
        "  \n",
        "  return fisher\n",
        "\n",
        "def compute_fisher_vec(model, x):\n",
        "  fisher = []\n",
        "  len_x = len(x)\n",
        "  for weight in weights:\n",
        "    fisher.append(K.zeros(weight.shape))\n",
        "    # data = np.expand_dims(data, axis=0)\n",
        "  probs = model.predict(x)\n",
        "  indx = np.argmax(probs,axis=1)\n",
        "  print(len(indx))\n",
        "  # grads = K.gradients(K.log(probs[indx]), weights)\n",
        "  grads = K.square(K.gradients(K.log(model.output), weights))\n",
        "  grads_compute = K.function(model.input, grads)\n",
        "  ders = grads_compute(x)\n",
        "  for i in range(len(weights)):\n",
        "    fisher[i] = K.reduce_sum(ders[i], axis=0)\n",
        "  # ders = K.reduce_sum(ders, axis=0)\n",
        "  # for w_indx in len(fisher):\n",
        "    # fisher[w_indx] = ders[w_indx]/len(x)\n",
        "  return fisher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRdUAQqmGHtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b7f72457-c5e5-4516-d7eb-181719e55e44"
      },
      "source": [
        "fim = compute_fisher(model, x_test[taskA_indx_test], num_samples=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0/200\n",
            "Iteration 100/200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfE1yRJDcHwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/fim1.npy',fim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfbZDNlcP9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fim = np.load('/content/drive/My Drive/fim1.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK1DZXkYDDz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "65ac5644-5bb1-4299-d465-31ca28e08af5"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer = EWC_Regularizer(0, fim, weights, True),\n",
        "#                   input_shape=(28,28,1)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Conv2D(64,(3,3), kernel_regularizer = EWC_Regularizer(1, fim, weights, True)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Conv2D(128,(3,3),padding='same', kernel_regularizer = EWC_Regularizer(2, fim, weights, True)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv2D(128,(3,3), padding='same', kernel_regularizer = EWC_Regularizer(3, fim, weights, True)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv2D(128,(3,3),padding='same', kernel_regularizer = EWC_Regularizer(4, fim, weights, True)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Flatten())\n",
        "model.add(Dense(128,input_shape=(28*28,), kernel_regularizer = EWC_Regularizer(0, fim, weights, True)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, kernel_regularizer = EWC_Regularizer(1, fim, weights, True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, kernel_regularizer = EWC_Regularizer(2, fim, weights, True)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
        " \n",
        "model.load_weights('/content/drive/My Drive/model/ewc_model_mnist.h5')\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtg_MysrGRn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d4f64f5-0e05-4575-f03d-0be6d020ed76"
      },
      "source": [
        "# taskB_callback = MultitaskCallback((x_test[taskB_indx_test], y_test[taskB_indx_test][:, 5:]),\n",
        "#                                    (x_test[taskA_indx_test], y_test[taskA_indx_test][:, :5]))\n",
        "# model.fit(x_train[taskB_indx_train], \n",
        "#           y_train[taskB_indx_train][:, 5:],\n",
        "#           callbacks=[taskB_callback],\n",
        "#           batch_size=32,\n",
        "#           epochs=5,\n",
        "#           validation_data=(x_test[taskB_indx_test], y_test[taskB_indx_test][:, 5:])\n",
        "#           )\n",
        "\n",
        "taskB_callback = MultitaskCallback((x_test[taskB_indx_test], y_test[taskB_indx_test]),\n",
        "                                   (x_test[taskA_indx_test], y_test[taskA_indx_test]))\n",
        "model.fit(x_train[taskB_indx_train], \n",
        "          y_train[taskB_indx_train],\n",
        "          callbacks=[taskB_callback],\n",
        "          batch_size=64,\n",
        "          epochs=9,\n",
        "          validation_data=(x_test[taskB_indx_test], y_test[taskB_indx_test])\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/10\n",
            "4861/4861 [==============================] - 0s 100us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.9885191917419434\n",
            " 672/4861 [===>..........................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.977648). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.489231). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.9887137413024902\n",
            "4861/4861 [==============================] - 0s 88us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.9887137413024902\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 87us/step\n",
            "Evaluation results Previous 0.9887137413024902\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.9885191917419434\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 1s 99us/step\n",
            "Evaluation results Previous 0.9883245825767517\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.9881299734115601\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.9883245825767517\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.9883245825767517\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.0\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.9881299734115601\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.00041143796988762915\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.9883245825767517\n",
            "4861/4861 [==============================] - 0s 96us/step\n",
            "Evaluation results Main 0.0022629089653491974\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.9879354238510132\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.004525817930698395\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.9869624376296997\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.013988891616463661\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.9861840605735779\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.032915037125349045\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.9848219752311707\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.055955566465854645\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.9813193082809448\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.07405883818864822\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.9778167009353638\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.08928204327821732\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.9727573394775391\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.09812795370817184\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.9680871963500977\n",
            "29404/29404 [==============================] - 21s 704us/step - loss: 8.0711 - accuracy: 0.8854 - val_loss: 3.8262 - val_accuracy: 0.1049\n",
            "Epoch 2/10\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.11211685091257095\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.9614710807800293\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.11725982278585434\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.9591360092163086\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.1219913586974144\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.9554387927055359\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.1326887458562851\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.9534928798675537\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.14256325364112854\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.9513524174690247\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.15490639209747314\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.9466822147369385\n",
            "4861/4861 [==============================] - 0s 86us/step\n",
            "Evaluation results Main 0.1612836867570877\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.9427904486656189\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.16724953055381775\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.9396770000457764\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.1793869584798813\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.9367581009864807\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.18802715837955475\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.9348122477531433\n",
            "4861/4861 [==============================] - 0s 96us/step\n",
            "Evaluation results Main 0.1956387609243393\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.9313095808029175\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.19995886087417603\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.9283907413482666\n",
            "4861/4861 [==============================] - 0s 98us/step\n",
            "Evaluation results Main 0.2034560739994049\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.9266394376754761\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.20695330202579498\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.9248881340026855\n",
            "4861/4861 [==============================] - 0s 96us/step\n",
            "Evaluation results Main 0.20921620726585388\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.9225530028343201\n",
            "4861/4861 [==============================] - 0s 100us/step\n",
            "Evaluation results Main 0.2085990607738495\n",
            "5139/5139 [==============================] - 0s 88us/step\n",
            "Evaluation results Previous 0.919050395488739\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.2102448046207428\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.91690993309021\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.21662209928035736\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.9134072661399841\n",
            "29404/29404 [==============================] - 20s 665us/step - loss: 4.6058 - accuracy: 0.7683 - val_loss: 2.3095 - val_accuracy: 0.2205\n",
            "Epoch 3/10\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.22197078168392181\n",
            "5139/5139 [==============================] - 1s 98us/step\n",
            "Evaluation results Previous 0.9122397303581238\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.22608517110347748\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.9102938175201416\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.22958238422870636\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.9095154404640198\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.22752520442008972\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.9093208909034729\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.22793664038181305\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.9083479046821594\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.22464513778686523\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.9077641367912292\n",
            "4861/4861 [==============================] - 0s 98us/step\n",
            "Evaluation results Main 0.2332853376865387\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.9073749780654907\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.23246245086193085\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.9027048349380493\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.23760543763637543\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.8978400230407715\n",
            "4861/4861 [==============================] - 0s 97us/step\n",
            "Evaluation results Main 0.23246245086193085\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8906401991844177\n",
            "4861/4861 [==============================] - 0s 88us/step\n",
            "Evaluation results Main 0.2388397455215454\n",
            "5139/5139 [==============================] - 0s 85us/step\n",
            "Evaluation results Previous 0.885580837726593\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.24151408672332764\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8818836212158203\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.24480558931827545\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8774080276489258\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.2524172067642212\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8776026368141174\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.25118288397789\n",
            "5139/5139 [==============================] - 0s 87us/step\n",
            "Evaluation results Previous 0.8776026368141174\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.24315984547138214\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8748784065246582\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.2371939867734909\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8713757395744324\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.24459987878799438\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8711811900138855\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.25118288397789\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8723487257957458\n",
            "29404/29404 [==============================] - 20s 697us/step - loss: 3.8314 - accuracy: 0.8427 - val_loss: 1.9472 - val_accuracy: 0.2508\n",
            "Epoch 4/10\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.25550296902656555\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8744891881942749\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.2579716145992279\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.8735162615776062\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.2614688277244568\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.872932493686676\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.2585887610912323\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8705974221229553\n",
            "4861/4861 [==============================] - 0s 97us/step\n",
            "Evaluation results Main 0.27072617411613464\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8705974221229553\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.27895495295524597\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.8690406680107117\n",
            "4861/4861 [==============================] - 0s 99us/step\n",
            "Evaluation results Main 0.29479530453681946\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.8676785230636597\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.30261263251304626\n",
            "5139/5139 [==============================] - 0s 88us/step\n",
            "Evaluation results Previous 0.8643705248832703\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.31166425347328186\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.8678731322288513\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.3248302936553955\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8670947551727295\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.3410820960998535\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8665109872817993\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.35486525297164917\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8600895404815674\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.37358567118644714\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8595057129859924\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.3826373219490051\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8565868735313416\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.3955976068973541\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8542518019676208\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.4019749164581299\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.8517221212387085\n",
            "4861/4861 [==============================] - 0s 96us/step\n",
            "Evaluation results Main 0.4062950015068054\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8429655432701111\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.4221353530883789\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8474411368370056\n",
            "29404/29404 [==============================] - 20s 669us/step - loss: 3.3040 - accuracy: 0.7588 - val_loss: 1.5706 - val_accuracy: 0.4279\n",
            "Epoch 5/10\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.43694713711738586\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8476357460021973\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.45278748869895935\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8495816588401794\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.4669820964336395\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.849970817565918\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.47644516825675964\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.847246527671814\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.48919975757598877\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.8437439203262329\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.4968113601207733\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8384899497032166\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.5021600723266602\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8351819515228271\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.5105945467948914\n",
            "5139/5139 [==============================] - 0s 88us/step\n",
            "Evaluation results Previous 0.8299279808998108\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.5233491063117981\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.830511748790741\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5299321413040161\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.830511748790741\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5400123596191406\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.8316793441772461\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.5424809455871582\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8277875185012817\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5451553463935852\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8244794607162476\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.5513268709182739\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8250632286071777\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.5599671006202698\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8258416056632996\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5632585883140564\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.8166958689689636\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.5651100873947144\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.8166958689689636\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.5646986365318298\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.8163066506385803\n",
            "29404/29404 [==============================] - 20s 665us/step - loss: 2.7558 - accuracy: 0.6960 - val_loss: 1.2678 - val_accuracy: 0.5653\n",
            "Epoch 6/10\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.5657272338867188\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.8155283331871033\n",
            " 608/4861 [==>...........................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.940206). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.470538). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.5743674039840698\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.8182525634765625\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5797160863876343\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.817863404750824\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5821847319602966\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.81513911485672\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.5860934257507324\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8143607974052429\n",
            "4861/4861 [==============================] - 0s 97us/step\n",
            "Evaluation results Main 0.5918534994125366\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.8145553469657898\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.5984365344047546\n",
            "5139/5139 [==============================] - 0s 88us/step\n",
            "Evaluation results Previous 0.8128040432929993\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.6044023633003235\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.8093014359474182\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.6109853982925415\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.803852915763855\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.6169512271881104\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.8005448579788208\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.6202427744865417\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7950963377952576\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.627648651599884\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7941233515739441\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.6362888216972351\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.803852915763855\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.6397860646247864\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.798404335975647\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.6441061496734619\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.8019070029258728\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.6500719785690308\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7954854965209961\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.6504834294319153\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.7913991212844849\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.6504834294319153\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.7962638735771179\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.6521291732788086\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7949017286300659\n",
            "29404/29404 [==============================] - 21s 699us/step - loss: 2.5095 - accuracy: 0.7503 - val_loss: 1.0868 - val_accuracy: 0.6527\n",
            "Epoch 7/10\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.6541863679885864\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7869235277175903\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.6529520750045776\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7849776148796082\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.6595350503921509\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.7793344855308533\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.66508948802948\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.7820587754249573\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.6634437441825867\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7810857892036438\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.6685867309570312\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7834209203720093\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.6700267195701599\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7840046882629395\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.6720839142799377\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7851722240447998\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.6749640107154846\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7793344855308533\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.680518388748169\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.766296923160553\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.6819584369659424\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7678536772727966\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.6842213273048401\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7740805745124817\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.6891586184501648\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.776610255241394\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.6926558613777161\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7764156460762024\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.6959473490715027\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.771161675453186\n",
            "4861/4861 [==============================] - 0s 95us/step\n",
            "Evaluation results Main 0.7047932744026184\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7622105479240417\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.7113762497901917\n",
            "5139/5139 [==============================] - 1s 97us/step\n",
            "Evaluation results Previous 0.7616267800331116\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.7222793698310852\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.7707725167274475\n",
            "29404/29404 [==============================] - 20s 666us/step - loss: 2.2851 - accuracy: 0.6957 - val_loss: 0.9562 - val_accuracy: 0.7225\n",
            "Epoch 8/10\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.7224850654602051\n",
            "5139/5139 [==============================] - 0s 88us/step\n",
            "Evaluation results Previous 0.7729130387306213\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7198107242584229\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.7762210369110107\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7261880040168762\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.770383358001709\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.734005331993103\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7624051570892334\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.7362682819366455\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.7639618515968323\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7385311722755432\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7645456194877625\n",
            "4861/4861 [==============================] - 0s 82us/step\n",
            "Evaluation results Main 0.739765465259552\n",
            "5139/5139 [==============================] - 1s 98us/step\n",
            "Evaluation results Previous 0.7573457956314087\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.7409998178482056\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7555944919586182\n",
            "4861/4861 [==============================] - 0s 87us/step\n",
            "Evaluation results Main 0.740588366985321\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.7518972754478455\n",
            "4861/4861 [==============================] - 0s 88us/step\n",
            "Evaluation results Main 0.7434684038162231\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7470325231552124\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.7451141476631165\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7538431882858276\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.7459370493888855\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.759875476360321\n",
            "4861/4861 [==============================] - 0s 89us/step\n",
            "Evaluation results Main 0.7473770976066589\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7610430121421814\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7500514388084412\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7563728094100952\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7543715238571167\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.7505351305007935\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.756840169429779\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.7497567534446716\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.756840169429779\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.7544269561767578\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7562230229377747\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.7503405213356018\n",
            "4861/4861 [==============================] - 0s 98us/step\n",
            "Evaluation results Main 0.7574573159217834\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7487838268280029\n",
            "29404/29404 [==============================] - 20s 692us/step - loss: 2.0991 - accuracy: 0.7320 - val_loss: 0.8641 - val_accuracy: 0.7581\n",
            "Epoch 9/10\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7599259614944458\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7464486956596375\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7588973641395569\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7456703782081604\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.761777400970459\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.7493675947189331\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7646574974060059\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7534539699554443\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7663032412528992\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7538431882858276\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7687718868255615\n",
            "5139/5139 [==============================] - 0s 96us/step\n",
            "Evaluation results Previous 0.7520918250083923\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7706233263015747\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7518972754478455\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7712404727935791\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.7456703782081604\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.774120569229126\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7446973919868469\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7778235077857971\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7450866103172302\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7804978489875793\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7425569295883179\n",
            "4861/4861 [==============================] - 0s 90us/step\n",
            "Evaluation results Main 0.7835836410522461\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7400272488594055\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.784612238407135\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.738275945186615\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7858465313911438\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.7394434809684753\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.7868751287460327\n",
            "5139/5139 [==============================] - 0s 90us/step\n",
            "Evaluation results Previous 0.7458649277687073\n",
            "4861/4861 [==============================] - 0s 99us/step\n",
            "Evaluation results Main 0.7883151769638062\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.7394434809684753\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.7868751287460327\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.7339949607849121\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.7866694331169128\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7353570461273193\n",
            "29404/29404 [==============================] - 20s 665us/step - loss: 1.9351 - accuracy: 0.6903 - val_loss: 0.7955 - val_accuracy: 0.7877\n",
            "Epoch 10/10\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7895494699478149\n",
            "5139/5139 [==============================] - 0s 91us/step\n",
            "Evaluation results Previous 0.739054262638092\n",
            "4861/4861 [==============================] - 0s 88us/step\n",
            "Evaluation results Main 0.7918123602867126\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.734189510345459\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7928409576416016\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7336057424545288\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.795103907585144\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7304922938346863\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7955152988433838\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7266005277633667\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.7944867014884949\n",
            "5139/5139 [==============================] - 0s 97us/step\n",
            "Evaluation results Previous 0.7225140929222107\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7969553470611572\n",
            "5139/5139 [==============================] - 1s 99us/step\n",
            "Evaluation results Previous 0.7275734543800354\n",
            "4861/4861 [==============================] - 0s 98us/step\n",
            "Evaluation results Main 0.7977782487869263\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7334111928939819\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.7979839444160461\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7345787286758423\n",
            "4861/4861 [==============================] - 0s 103us/step\n",
            "Evaluation results Main 0.800864040851593\n",
            "5139/5139 [==============================] - 0s 95us/step\n",
            "Evaluation results Previous 0.7306869029998779\n",
            "4861/4861 [==============================] - 1s 104us/step\n",
            "Evaluation results Main 0.8031269311904907\n",
            "5139/5139 [==============================] - 1s 103us/step\n",
            "Evaluation results Previous 0.7244600057601929\n",
            "4861/4861 [==============================] - 1s 103us/step\n",
            "Evaluation results Main 0.8070355653762817\n",
            "5139/5139 [==============================] - 1s 107us/step\n",
            "Evaluation results Previous 0.7207627892494202\n",
            "4861/4861 [==============================] - 0s 101us/step\n",
            "Evaluation results Main 0.8070355653762817\n",
            "5139/5139 [==============================] - 1s 106us/step\n",
            "Evaluation results Previous 0.7225140929222107\n",
            "4861/4861 [==============================] - 0s 100us/step\n",
            "Evaluation results Main 0.8070355653762817\n",
            "5139/5139 [==============================] - 1s 107us/step\n",
            "Evaluation results Previous 0.7242653965950012\n",
            "4861/4861 [==============================] - 0s 94us/step\n",
            "Evaluation results Main 0.8068298697471619\n",
            "5139/5139 [==============================] - 0s 89us/step\n",
            "Evaluation results Previous 0.7308815121650696\n",
            "4861/4861 [==============================] - 0s 92us/step\n",
            "Evaluation results Main 0.8095042109489441\n",
            "5139/5139 [==============================] - 0s 94us/step\n",
            "Evaluation results Previous 0.7252383828163147\n",
            "4861/4861 [==============================] - 0s 91us/step\n",
            "Evaluation results Main 0.8125900030136108\n",
            "5139/5139 [==============================] - 0s 93us/step\n",
            "Evaluation results Previous 0.7197898626327515\n",
            "4861/4861 [==============================] - 0s 93us/step\n",
            "Evaluation results Main 0.8136186003684998\n",
            "5139/5139 [==============================] - 0s 92us/step\n",
            "Evaluation results Previous 0.718816876411438\n",
            "29404/29404 [==============================] - 20s 689us/step - loss: 1.7985 - accuracy: 0.6558 - val_loss: 0.7321 - val_accuracy: 0.8153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f097ddabcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENrhfBLoD6Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(taskB_callback.main_task_preds))\n",
        "print(len(taskB_callback.previous_task_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxsPslCrwmNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "e5b0ca4d-e413-4f99-81bf-b3841a1b084a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig,(ax1,ax2) = plt.subplots(1,2, figsize=(14,5))\n",
        "ax1.set_title(\"Task A performance\")\n",
        "ax1.plot(taskA_callback.main_task_preds, label='Task A')\n",
        "ax1.legend()\n",
        "ax2.set_title(\"Task A and B performance\")\n",
        "ax2.plot(taskB_callback.main_task_preds, label=\"TaskB\")\n",
        "ax2.plot(taskB_callback.previous_task_preds, label='Task A')\n",
        "ax2.legend()\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/My Drive/hw3_1b_exp.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chlkzx8ChMsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.random.randint(1,5,(3,3))\n",
        "b = np.random.randint(1,5,(3,3))\n",
        "c = np.random.randint(1,5,(3,3))\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "d = np.add.reduce([a,b,c])\n",
        "print(d)\n",
        "print(a+b+c)\n",
        "e = K.sum(a+b+c)\n",
        "print(e)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}