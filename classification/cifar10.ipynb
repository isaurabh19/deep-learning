{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l918Z7REL2PK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cac1ef34-89a0-4afa-e66d-a9669ac32c25"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(\"Done loading data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 7s 0us/step\n",
            "Done loading data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP8_RCB8vC_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "73fca34c-2029-4648-90be-2c59cdf97513"
      },
      "source": [
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(\"y_train shape:\",y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LovMgoG7MVK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9adec5f7-2547-4399-e63f-f98dc06885fb"
      },
      "source": [
        "import keras\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDGdRaZCVowP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "outputId": "798533e1-f59d-41e5-838c-da775db8a532"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128,(3,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128,(3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128,(3,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 3,734,090\n",
            "Trainable params: 3,734,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pxx_dTJzOAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "957b490f-15d9-4784-89e2-03b79c653dfa"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "batch_size = 32\n",
        "epochs = 25\n",
        "import time\n",
        "tensorboard = keras.callbacks.TensorBoard('/content/drive/My Drive/logs/std/x5')\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              verbose=1,\n",
        "          callbacks=[tensorboard])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 20s 409us/step - loss: 2.3040 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 2.3040 - accuracy: 0.0998 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 20s 401us/step - loss: 2.3039 - accuracy: 0.0988 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 2.3036 - accuracy: 0.1012 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 19s 389us/step - loss: 2.3036 - accuracy: 0.0999 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 2.3037 - accuracy: 0.1019 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 20s 398us/step - loss: 2.3037 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 20s 399us/step - loss: 2.3035 - accuracy: 0.0990 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 2.3036 - accuracy: 0.0993 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 20s 399us/step - loss: 2.3036 - accuracy: 0.1015 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 20s 401us/step - loss: 2.3037 - accuracy: 0.0994 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 2.3037 - accuracy: 0.0970 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 2.3035 - accuracy: 0.0966 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 21s 410us/step - loss: 2.3036 - accuracy: 0.0990 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 21s 413us/step - loss: 2.3035 - accuracy: 0.0979 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 2.3036 - accuracy: 0.0987 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 2.3034 - accuracy: 0.0983 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 20s 396us/step - loss: 2.3034 - accuracy: 0.1000 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 2.3036 - accuracy: 0.0998 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 20s 399us/step - loss: 2.3036 - accuracy: 0.0987 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 20s 400us/step - loss: 2.3036 - accuracy: 0.0975 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 20s 398us/step - loss: 2.3035 - accuracy: 0.0987 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 20s 406us/step - loss: 2.3036 - accuracy: 0.0972 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 20s 398us/step - loss: 2.3035 - accuracy: 0.0979 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 20s 391us/step - loss: 2.3036 - accuracy: 0.0997 - val_loss: 2.3034 - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f96c4167940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFeMOnVFxy8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6982e091-779c-4d5c-9664-27488221ea3d"
      },
      "source": [
        "save_dir = '/content/drive/My Drive/model/'\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/drive/My Drive/model/keras_cifar10_trained_model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX4VUUjWGNls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3a78d950-0929-42fa-e5c0-7f750d0046f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !ls '/content/drive/My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JdQJjA0gLVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import os\n",
        "save_dir = '/content/drive/My Drive/model'\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "model = load_model(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP9LTBxb9KPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(5)\n",
        "layer_vis = [1]\n",
        "for layer_no in layer_vis:\n",
        "  image_nos = np.random.choice(range(100), size=100, replace=False)\n",
        "  last_conv = model.get_layer('conv2d_{}'.format(layer_no))\n",
        "  print(\"Layer : {}\".format(layer_no))\n",
        "  random_feature_maps = np.random.choice(range(last_conv.filters), size=3, replace=False)\n",
        "  print(\"Random feature numbers are {}\".format(random_feature_maps))\n",
        "  feature_map_activations = []\n",
        "  feature_gradients = []\n",
        "  for image_no in image_nos:\n",
        "    image = x_test[image_no]\n",
        "    # print(image_no)\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "    img = np.expand_dims(image, axis=0)\n",
        "\n",
        "    predict = model.predict(img)\n",
        "    target_class = np.argmax(predict[0])\n",
        "    # print(\"Target Class = %d\"%target_class)\n",
        "\n",
        "    grads = K.gradients(model.output[:,target_class],last_conv.output)[0]\n",
        "\n",
        "    pooled_grads = K.mean(grads,axis=(0,1,2))\n",
        "    iterate = K.function([model.input],[pooled_grads,last_conv.output[0]])\n",
        "    pooled_grads_value,conv_layer_output = iterate([img])\n",
        "    feature_map_activations.append([\n",
        "                                    conv_layer_output[:,:,random_feature_maps[0]],\n",
        "                                    conv_layer_output[:,:,random_feature_maps[1]],\n",
        "                                    conv_layer_output[:,:,random_feature_maps[2]]\n",
        "                                    ])\n",
        "    feature_gradients.append([\n",
        "      pooled_grads_value[random_feature_maps[0]],\n",
        "      pooled_grads_value[random_feature_maps[1]],\n",
        "      pooled_grads_value[random_feature_maps[2]]]\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHmq210Rj1uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  feature_activations_np = np.array(feature_map_activations)\n",
        "  feature_gradients_np =  np.array(feature_gradients)\n",
        "  max_grads_indices = np.argmax(feature_gradients_np, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CTVtKO7mRmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Feature gradients {}\".format(feature_gradients_np))\n",
        "print(\"Max gradient images :{}\".format(max_grads_indices))\n",
        "col=0\n",
        "for index in max_grads_indices:\n",
        "  # print(\"Max gradient {} for feature {}\".format(feature_gradients_np[index][col], col))\n",
        "  heatmap = feature_activations_np[index][col] * feature_gradients_np[index][col]\n",
        "  for x in range(heatmap.shape[0]):\n",
        "    for y in range(heatmap.shape[1]):\n",
        "        heatmap[x,y] = np.max(heatmap[x,y],0)\n",
        "\n",
        "  print(\"Showing results for layer {} and feature {}\".format(layer_no, random_feature_maps[col]))\n",
        "  image = x_test[image_nos[index]]\n",
        "  print(image_nos[index])\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "  fig,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,4))\n",
        "  fig.suptitle(\"Layer Conv2d_{} Feature {}\".format(layer_no, random_feature_maps[col]))\n",
        "  ax1.set_title('Original Image')\n",
        "  ax1.imshow(image)\n",
        "  print(\"heatmap\")\n",
        "  heatmap = np.maximum(heatmap,0)\n",
        "  heatmap /= np.max(heatmap)\n",
        "  # plt.imshow(heatmap)\n",
        "  # plt.show()\n",
        "  ax2.imshow(heatmap)\n",
        "  print(\"overlay\")\n",
        "  upsample = resize(heatmap, (32,32),preserve_range=True)\n",
        "  # plt.imshow(image)\n",
        "  # plt.imshow(upsample,alpha=0.5)\n",
        "  # plt.show()\n",
        "  ax3.imshow(image)\n",
        "  ax3.imshow(upsample,alpha=0.5)\n",
        "  fig.savefig(\"/content/drive/My Drive/layer_{}_feature_{}.png\".\n",
        "              format(layer_no, random_feature_maps[col]))\n",
        "  col+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2RJkd6tmIdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_grad_indices = np.argsort(feature_gradients_np, axis=0)[::-1][:2]\n",
        "# print(\"Sorted grad indices {}\".format(sorted_grad_indices))\n",
        "# print(\"Feature gradients {}\".format(feature_gradients_np))\n",
        "c=0\n",
        "for col in sorted_grad_indices.T:\n",
        "  for r in col:\n",
        "    print(\"Pooled grad value {}\".format(feature_gradients_np[r][c]))\n",
        "    heatmap = feature_activations_np[r][c] * feature_gradients_np[r][c]\n",
        "    for x in range(heatmap.shape[0]):\n",
        "      for y in range(heatmap.shape[1]):\n",
        "        heatmap[x,y] = np.max(heatmap[x,y],0)\n",
        "\n",
        "    print(\"Showing results for layer {} and feature {}\".format(layer_no, random_feature_maps[c]))\n",
        "    image = x_test[image_nos[r]]\n",
        "    print(image_nos[r])\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "    fig,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,4))\n",
        "    fig.suptitle(\"Layer Conv2d_{} Feature {}\".format(layer_no, random_feature_maps[c]))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax1.imshow(image)\n",
        "    print(\"heatmap\")\n",
        "    heatmap = np.maximum(heatmap,0)\n",
        "    # print(\"Maximum(heatmap,0) {}\".format(heatmap))\n",
        "    heatmap /= np.max(heatmap)\n",
        "    # plt.imshow(heatmap)\n",
        "    # plt.show()\n",
        "    ax2.set_title(\"Heatmap\")\n",
        "    ax2.imshow(heatmap)\n",
        "\n",
        "    print(\"overlay\")\n",
        "    upsample = resize(heatmap, (32,32),preserve_range=True)\n",
        "    # plt.imshow(image)\n",
        "    # plt.imshow(upsample,alpha=0.5)\n",
        "    # plt.show()\n",
        "    ax3.set_title(\"Overlay\")\n",
        "    ax3.imshow(image)\n",
        "    ax3.imshow(upsample, alpha=0.5)\n",
        "    fig.savefig(\"/content/drive/My Drive/Image_{}_layer_{}_feature_{}.png\".\n",
        "              format(image_nos[r],layer_no, random_feature_maps[c]))\n",
        "  c+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW1hK7NEEfK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/My Drive/logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGe5ErUfx5ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7foHpe4gFWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(len(model.layers)):\n",
        "# \tlayer = model.layers[i]\n",
        "# \t# check for convolutional layer\n",
        "# \tif 'conv' not in layer.name:\n",
        "# \t\tcontinue\n",
        "# \t# summarize output shape\n",
        "# \tprint(i, layer.name, layer.output.shape)\n",
        "for i in range(len(model.layers)):\n",
        "  conv_model = keras.Model(inputs=model.inputs, outputs=model.layers[i].output)\n",
        "  act_model = keras.Model(inputs=model.inputs,outputs=model.layers[i+1].output)\n",
        "print(v_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4-23Y_-nIyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "# img = load_img(x_test[0], target_size=(32,32))\n",
        "\n",
        "# # convert the image to an array\n",
        "# img = img_to_array(img)\n",
        "# # expand dimensions so that it represents a single 'sample'\n",
        "img = x_test[1]\n",
        "pyplot.imshow(img)\n",
        "pyplot.show()\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "feature_maps = v_model.predict(img)\n",
        "square = 4\n",
        "ix = 1\n",
        "for _ in range(square):\n",
        "  for _ in range(square):\n",
        "    # specify subplot and turn of axis\n",
        "    # ax = pyplot.subplot(square, square, ix)\n",
        "    # ax.set_xticks([])\n",
        "    # ax.set_yticks([])\n",
        "    # plot filter channel in grayscale\n",
        "    pyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
        "    pyplot.show()\n",
        "    ix += 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}